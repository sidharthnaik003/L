{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7BGI_5n4TCd_",
        "outputId": "31336cfa-f99c-4cb1-a000-32202506068c"
      },
      "outputs": [],
      "source": [
        "pip install numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hhxBOcvcTCeC",
        "outputId": "b53e631b-e374-4566-cf86-af6c1e02c653"
      },
      "outputs": [],
      "source": [
        "pip install pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B1ypCge9TCeC",
        "outputId": "3f6997e2-67bf-4ac4-82d4-5ddbab014d72"
      },
      "outputs": [],
      "source": [
        "pip install matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CVQCYe71TCeD",
        "outputId": "6a105e55-f003-43ac-80ba-9e671e3ec793"
      },
      "outputs": [],
      "source": [
        "pip install seaborn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D87TKTF3TCeD",
        "outputId": "9b7883fa-8fc8-49ff-904b-a1fa5aff758d"
      },
      "outputs": [],
      "source": [
        "pip install bokeh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g-H4WF_GTCeD",
        "outputId": "965a3982-6dc1-41e5-b9ff-9d96b834271e"
      },
      "outputs": [],
      "source": [
        "pip install folium"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3A3qbRW9TCeE",
        "outputId": "09026fe7-c9f0-4d00-c917-d0f8cffa4cec"
      },
      "outputs": [],
      "source": [
        "pip install geoplot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n1hTyBjNTCeE",
        "outputId": "5f1d3b95-5a28-4b00-b4d8-d64b92b0c812"
      },
      "outputs": [],
      "source": [
        "pip install geoplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pip install geoplotlib\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5y0-QVNWTCeE",
        "outputId": "c02d54dd-e8f8-44d0-b3c3-8c86aaf28a88"
      },
      "outputs": [],
      "source": [
        "pip install --upgrade pip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kq80ih_KTCeE",
        "outputId": "23370c3b-1575-438e-a7ee-a58d1f1cb435"
      },
      "outputs": [],
      "source": [
        "#1a\n",
        "\n",
        "import numpy as np\n",
        "data =np.array([1,2,3,4,5,6,7,8,9,10])\n",
        "mean=np.mean(data)\n",
        "median=np.median(data)\n",
        "variance=np.var(data)\n",
        "std_dev=np.std(data)\n",
        "print(\"mean:\",mean)\n",
        "print(\"median:\",median)\n",
        "print(\"variance:\",variance)\n",
        "print(\"standard deviation:\",std_dev)\n",
        "print(\"element at index 2:\",data[2])\n",
        "sliced_data=data[2:6]\n",
        "print(\"sliced data from index 2 to 5\",sliced_data)\n",
        "split_data=np.array_split(data,2)\n",
        "print(\"split data:\",split_data)\n",
        "print(\"iterating over elements\")\n",
        "for element in data:\n",
        "    print(element)\n",
        "filter_data=data[data>5]\n",
        "print(\"filtered data:\",filter_data)\n",
        "sorted_data=np.sort(data)\n",
        "print(\"sorted data:\",sorted_data)\n",
        "additional_data=np.array([11,12,13])\n",
        "combined_data=np.concatenate((data,additional_data))\n",
        "print(\"combined data:\",combined_data)\n",
        "reshaped_data=data.reshape(2,5)\n",
        "print(\"reshaped data(2x5):\",reshaped_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y7UaFQxjTCeF",
        "outputId": "f6305b44-fa84-4674-e2b0-6e7ff1647515"
      },
      "outputs": [],
      "source": [
        "#1b\n",
        "\n",
        "import pandas as pd\n",
        "data= pd.Series([1,2,3,4,5,6,7,8,9,10])\n",
        "mean=data.mean()\n",
        "median=data.median()\n",
        "variance=data.var()\n",
        "std_dev=data.std()\n",
        "print(\"mean:\",mean)\n",
        "print(\"median:\",median)\n",
        "print(\"variance:\",variance)\n",
        "print(\"standard deviation:\",std_dev)\n",
        "print(\"element at index 2:\",data[2])\n",
        "sliced_data=data[2:6]\n",
        "print(\"sliced data from index 2 to 5\",sliced_data)\n",
        "print(\"iterating over elements\")\n",
        "for element in data:\n",
        "    print(element)\n",
        "filter_data=data[data>5]\n",
        "print(\"filtered data:\",filter_data)\n",
        "sorted_data=data.sort_values()\n",
        "print(\"sorted data:\",sorted_data)\n",
        "df=pd.DataFrame({'values':data})\n",
        "reshaped_data=df.values.reshape(2,5)\n",
        "print(\"reshaped data(2x5):\",reshaped_data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "Exnf1Vn8TCeG",
        "outputId": "914c8654-1d2c-45f5-d958-501bb52107d6"
      },
      "outputs": [],
      "source": [
        "#2 a\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "google = pd.read_csv('GOOGL_data.csv')\n",
        "facebook = pd.read_csv('FB_data.csv')\n",
        "apple = pd.read_csv('AAPL_data.csv')\n",
        "amazon = pd.read_csv('AMZN_data.csv')\n",
        "microsoft = pd.read_csv('MSFT_data.csv')\n",
        "\n",
        "for df in [google, facebook, apple, amazon, microsoft]:\n",
        "    df['date'] = pd.to_datetime(df['date'])\n",
        "\n",
        "plt.figure(figsize=(16, 8), dpi=300)\n",
        "plt.plot(google['date'], google['close'], label='Google')\n",
        "plt.plot(facebook['date'], facebook['close'], label='Facebook')\n",
        "plt.plot(apple['date'], apple['close'], label='Apple')\n",
        "plt.plot(amazon['date'], amazon['close'], label='Amazon')\n",
        "plt.plot(microsoft['date'], microsoft['close'], label='Microsoft')\n",
        "\n",
        "plt.xticks(rotation=70)\n",
        "plt.yticks(np.arange(0, 1450, 100))\n",
        "plt.title('Stock Trend', fontsize=16)\n",
        "plt.ylabel('Closing Price in $', fontsize=14)\n",
        "plt.grid()\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nWK6oH7-TCeG"
      },
      "outputs": [],
      "source": [
        "#2b\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "movie_scores = pd.read_csv('movie_scores.csv')\n",
        "\n",
        "plt.figure(figsize=(10, 5), dpi=300)\n",
        "pos = np.arange(len(movie_scores['MovieTitle']))\n",
        "width = 0.3\n",
        "plt.bar(pos - width / 2, movie_scores['Tomatometer'], width, label='Tomatometer')\n",
        "plt.bar(pos + width / 2, movie_scores['AudienceScore'], width, label='Audience Score')\n",
        "plt.xticks(pos, rotation=10)\n",
        "plt.yticks(np.arange(0, 101, 20))\n",
        "\n",
        "ax = plt.gca()\n",
        "ax.set_xticklabels(movie_scores['MovieTitle'])\n",
        "ax.set_yticklabels(['0%', '20%', '40%', '60%', '80%', '100%'])\n",
        "ax.set_yticks(np.arange(0, 100, 5), minor=True)\n",
        "ax.yaxis.grid(which='major')\n",
        "ax.yaxis.grid(which='minor', linestyle='--')\n",
        "\n",
        "plt.title('Movie comparison')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tTwRWMgwTCeG"
      },
      "outputs": [],
      "source": [
        "#2c\n",
        "import pandas as sb\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "bills = sns.load_dataset('tips')\n",
        "days = ['Thur', 'Fri', 'Sat', 'Sun']\n",
        "days_range = np.arange(len(days))\n",
        "smoker = ['Yes', 'No']\n",
        "bills_by_days = [bills[bills['day'] == day] for day in days]\n",
        "bills_by_days_smoker = [[bills_by_days[day][bills_by_days[day]['smoker'] == s] for s in smoker] for day in days_range]\n",
        "total_by_days_smoker = [[bills_by_days_smoker[day][s]['total_bill'].sum() for s in range(len(smoker))] for day in days_range]\n",
        "totals = np.asarray(total_by_days_smoker)\n",
        "\n",
        "plt.figure(figsize=(10, 5), dpi=300)\n",
        "plt.bar(days_range, totals[:, 0], label='Smoker')\n",
        "plt.bar(days_range, totals[:, 1], bottom=totals[:, 0], label='Non-smoker')\n",
        "plt.legend()\n",
        "plt.xticks(days_range)\n",
        "ax = plt.gca()\n",
        "ax.set_xticklabels(days)\n",
        "ax.yaxis.grid()\n",
        "plt.ylabel('Daily total sales in $')\n",
        "plt.title('Restaurant performance')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CouVuGHITCeH"
      },
      "outputs": [],
      "source": [
        "#2d\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "sales = pd.read_csv('smartphone_sales.csv')\n",
        "plt.figure(figsize=(10, 6), dpi=300)\n",
        "labels = sales.columns[2:]\n",
        "plt.stackplot(sales['Quarter'], sales['Apple'], sales['Samsung'], sales['Huawei'], sales['Xiaomi'], sales['OPPO'], labels=labels, data=sales)\n",
        "plt.legend()\n",
        "plt.xlabel('Quarters')\n",
        "plt.ylabel('Sales units in thousands')\n",
        "plt.title('Smartphone sales units')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UgecdoYYTCeH"
      },
      "outputs": [],
      "source": [
        "#3a\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "data = [np.random.randint(50,141) for _ in range(100)]\n",
        "plt.figure(figsize=(6, 4),dpi=150)\n",
        "plt.hist(data, bins=10)\n",
        "plt.axvline(x=100,color='r')\n",
        "plt.axvline(x=115,color='r',linestyle='--')\n",
        "plt.axvline(x=85,color='r',linestyle='--')\n",
        "plt.xlabel('IQ')\n",
        "plt.ylabel('Freq')\n",
        "plt.title('IQ for a test')\n",
        "plt.show()\n",
        "plt.figure(figsize=(6,4),dpi=150)\n",
        "plt.boxplot(data)\n",
        "ax = plt.gca()\n",
        "ax.set_xticklabels(['Test group'])\n",
        "plt.ylabel('IQ score')\n",
        "plt.title('IQ for a test')\n",
        "plt.show()\n",
        "ga=[np.random.randint(50,141) for _ in range(100)]\n",
        "gb=[np.random.randint(50,141) for _ in range(100)]\n",
        "gc=[np.random.randint(50,141) for _ in range(100)]\n",
        "gd=[np.random.randint(50,141) for _ in range(100)]\n",
        "plt.figure(figsize=(6,4),dpi=150)\n",
        "plt.boxplot([ga,gb,gc,gd])\n",
        "ax = plt.gca()\n",
        "ax.set_xticklabels(['GA','GB','GC','GD'])\n",
        "plt.ylabel('IQ score')\n",
        "plt.title('IQ for dif test')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yMT_zRN_TCeI"
      },
      "outputs": [],
      "source": [
        "# 3b\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Ensure inline plotting in Jupyter notebooks\n",
        "get_ipython().run_line_magic('matplotlib', 'inline')\n",
        "\n",
        "# Load the data\n",
        "data = pd.read_csv('anage_data.csv')\n",
        "\n",
        "# Define the columns for longevity and mass\n",
        "longevity = 'Maximum longevity (yrs)'  # Check the exact column name in your CSV\n",
        "mass = 'Body mass (g)'  # Check the exact column name in your CSV\n",
        "\n",
        "# Filter out rows with non-finite values in the specified columns\n",
        "data = data[np.isfinite(data[longevity]) & np.isfinite(data[mass])]\n",
        "\n",
        "# Filter the data for class 'Aves'\n",
        "aves = data[data['Class'] == 'Aves']\n",
        "\n",
        "# Further filter for body mass less than 2000 grams\n",
        "aves = aves[aves[mass] < 2000]\n",
        "\n",
        "# Create the figure and gridspec layout\n",
        "fig = plt.figure(figsize=(8, 8), dpi=150, constrained_layout=True)\n",
        "gs = fig.add_gridspec(4, 4)\n",
        "\n",
        "# Create the subplots\n",
        "histx_ax = fig.add_subplot(gs[0, :-1])\n",
        "histy_ax = fig.add_subplot(gs[1:, -1])\n",
        "scatter_ax = fig.add_subplot(gs[1:, :-1])\n",
        "\n",
        "# Scatter plot\n",
        "scatter_ax.scatter(aves[mass], aves[longevity])\n",
        "\n",
        "# Histograms\n",
        "histx_ax.hist(aves[mass], bins=20, density=True)\n",
        "histx_ax.set_xticks([])\n",
        "\n",
        "histy_ax.hist(aves[longevity], bins=20, density=True, orientation='horizontal')\n",
        "histy_ax.set_yticks([])\n",
        "\n",
        "# Set labels\n",
        "scatter_ax.set_xlabel('Body mass (g)')\n",
        "scatter_ax.set_ylabel('Maximum longevity (yrs)')\n",
        "\n",
        "# Set the title\n",
        "fig.suptitle('Scatter plot with marginal histograms')\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# 3c\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "# Load images\n",
        "image_folder = 'images'\n",
        "img_filenames = sorted(os.listdir(image_folder))\n",
        "\n",
        "# Ensure only image files are selected\n",
        "# (you can adjust this to check for specific extensions if needed)\n",
        "img_filenames = [f for f in img_filenames if f.endswith(('.png', '.jpg', '.jpeg'))]\n",
        "\n",
        "# Load the images\n",
        "imgs = [mpimg.imread(os.path.join(image_folder, img_filename)) for img_filename in img_filenames]\n",
        "\n",
        "# Create a subplot grid of 2x2\n",
        "fig, axes = plt.subplots(2, 2)\n",
        "\n",
        "# Set figure size and DPI\n",
        "fig.set_size_inches(6, 6)\n",
        "fig.dpi = 150\n",
        "axes = axes.ravel()\n",
        "\n",
        "# Specify labels for each image\n",
        "labels = ['coast', 'beach', 'building', 'city at night']\n",
        "\n",
        "# Plot images in the subplots\n",
        "for i in range(len(imgs)):\n",
        "    axes[i].imshow(imgs[i])\n",
        "    axes[i].set_xticks([]) # Remove x-axis ticks\n",
        "    axes[i].set_yticks([]) # Remove y-axis ticks\n",
        "    axes[i].set_xlabel(labels[i]) # Add labels to the subplots\n",
        "\n",
        "# Display the plot\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WUNJdV4QTCeI"
      },
      "outputs": [],
      "source": [
        "#3d\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "group_a = [118,103,125,107,111,96,104,97,96,114,96,75,114,107,87,117,117,114,117,122,107,133,94,91,118,110,117,86,143,83,106,86,98,126,109,91,112,109,91,112,120,108,111,107,96,89,113,117,81,113,112,84,115,96,93,128,115,138,121,87,113,110,79,100,84,115,93,108,130,107,16,181,117,93,94,103,112,98,103,70,139,94,110,105,122,94,94,105,129,110,12,97,109,121,106,118,131,88,121,125,93,78]\n",
        "group_b = [120, 105, 127, 109, 113, 98, 106, 99, 98, 116, 98, 77, 116, 109, 89, 119, 119, 116, 119, 124, 109, 135, 96, 93, 120, 112, 119, 88, 145, 85, 108, 88, 100, 128, 111, 93, 114, 111, 93, 114, 122, 110, 113, 109, 98, 91, 115, 119, 83, 115, 114, 86, 117, 98, 95, 130, 117, 140, 123, 89, 115, 112, 81, 102, 86, 117, 95, 110, 132, 109, 18, 183, 119, 95, 96, 105, 114, 100, 105, 72, 141, 96, 112, 107, 124, 96, 96, 107, 131, 112, 14, 99, 111, 123, 108, 120, 133, 90, 123, 127, 95, 80]\n",
        "group_c = [122, 107, 129, 111, 115, 100, 108, 101, 100, 118, 100, 79, 118, 111, 91, 121, 121, 118, 121, 126, 111, 137, 98, 95, 122, 114, 121, 90, 147, 87, 110, 90, 102, 130, 113, 95, 116, 113, 95, 116, 124, 112, 115, 111, 100, 93, 117, 121, 85, 117, 116, 88, 119, 100, 97, 132, 119, 142, 125, 91, 117, 114, 83, 104, 88, 119, 97, 112, 134, 111, 20, 185, 121, 97, 98, 107, 116, 102, 107, 74, 143, 98, 114, 109, 126, 98, 98, 109, 133, 114, 16, 101, 113, 125, 110, 122, 135, 92, 125, 129, 97, 82]\n",
        "group_d = [124, 109, 131, 113, 117, 102, 110, 103, 102, 120, 102, 81, 120, 113, 93, 123, 123, 120, 123, 128, 113, 139, 100, 97, 124, 116, 123, 92, 149, 89, 112, 92, 104, 132, 115, 97, 118, 115, 97, 118, 126, 114, 117, 113, 102, 95, 119, 123, 87, 119, 118, 90, 121, 102, 99, 134, 121, 144, 127, 93, 119, 116, 85, 106, 90, 121, 99, 114, 136, 113, 22, 187, 123, 99, 100, 109, 118, 104, 109, 76, 145, 100, 116, 111, 128, 100, 100, 111, 135, 116, 18, 103, 115, 127, 112, 124, 137, 94, 127, 131, 99, 84]\n",
        "\n",
        "plt.figure(figsize=(12,8),dpi=150)\n",
        "plt.subplot(2,2,1)\n",
        "plt.scatter(group_a,group_b,color=\"blue\")\n",
        "plt.xlabel('Group A')\n",
        "plt.ylabel('Group B')\n",
        "plt.title('Group A vs Group B')\n",
        "plt.subplot(2,2,2)\n",
        "plt.scatter(group_a,group_c,color=\"green\")\n",
        "plt.xlabel('Group A')\n",
        "plt.ylabel('Group C')\n",
        "plt.title('Group A vs Group C')\n",
        "plt.subplot(2,2,3)\n",
        "plt.scatter(group_a,group_d,color=\"red\")\n",
        "plt.xlabel('Group A')\n",
        "plt.ylabel('Group D')\n",
        "plt.title('Group A vs Group D')\n",
        "plt.subplot(2,2,4)\n",
        "plt.scatter(group_b,group_c,color=\"purple\")\n",
        "plt.xlabel('Group b')\n",
        "plt.ylabel('Group c')\n",
        "plt.title('Group B vs Group C')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UPb-e5lTTCeI"
      },
      "outputs": [],
      "source": [
        "# 4\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "sns.set()\n",
        "data = pd.read_csv('northern_surface_temperature.csv',index_col = ['Year'])\n",
        "data = data.transpose()\n",
        "heat_colormap = sns.diverging_palette(240,15,s=99,as_cmap=True)\n",
        "plt.figure(dpi=200)\n",
        "sns.heatmap(data.iloc[:,::5],cmap=heat_colormap,center=0)\n",
        "plt.title(\"Temperature Changes from 1880 to 2015(base perioud 1951-1980)\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 5\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Define kernel function for local weighted regression\n",
        "def kernel(point, xmat, k):\n",
        "    m, n = np.shape(xmat)\n",
        "    weights = np.asmatrix(np.eye(m))\n",
        "    for j in range(m):\n",
        "        diff = point - xmat[j]\n",
        "        weights[j, j] = np.exp(diff * diff.T / (-2.0 * k**2))\n",
        "    return weights\n",
        "\n",
        "# Define function for local weighted regression\n",
        "def localWeight(point, xmat, ymat, k):\n",
        "    wei = kernel(point, xmat, k)\n",
        "    W = (xmat.T * (wei * xmat)).I * (xmat.T * (wei * ymat.T))\n",
        "    return W\n",
        "\n",
        "# Define function for performing local weighted regression on the dataset\n",
        "def localWeightRegression(xmat, ymat, k):\n",
        "    m, n = np.shape(xmat)\n",
        "    ypred = np.zeros(m)\n",
        "    for i in range(m):\n",
        "        ypred[i] = xmat[i] * localWeight(xmat[i], xmat, ymat, k)\n",
        "    return ypred\n",
        "\n",
        "# Load data points\n",
        "data = pd.read_csv('10-dataset.csv')  # Ensure you have the correct path to this CSV\n",
        "bill = np.array(data.total_bill)\n",
        "tip = np.array(data.tip)\n",
        "\n",
        "# Preparing and adding 1 to bill\n",
        "mbill = np.asmatrix(bill)\n",
        "mtip = np.asmatrix(tip)\n",
        "\n",
        "m = np.shape(mbill)[1]\n",
        "one = np.asmatrix(np.ones(m))\n",
        "X = np.hstack((one.T, mbill.T))\n",
        "\n",
        "# Set k for local weighted regression\n",
        "ypred = localWeightRegression(X, mtip, 0.5)\n",
        "\n",
        "# Sorting for smooth plotting\n",
        "SortIndex = X[:, 1].argsort(0)\n",
        "xsort = X[SortIndex][:, 0]\n",
        "\n",
        "# Plotting the data and the regression line\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(1, 1, 1)\n",
        "ax.scatter(bill, tip, color='green')\n",
        "ax.plot(xsort[:, 1], ypred[SortIndex], color='red', linewidth=5)\n",
        "plt.xlabel('Total bill')\n",
        "plt.ylabel('Tip')\n",
        "plt.show()\n",
        "\n",
        "# Load another dataset for statistical operations\n",
        "dataset = np.genfromtxt('normal_distribution.csv', delimiter=',')\n",
        "print(\"Dataset shape:\", dataset.shape)  # Print the shape of the dataset\n",
        "\n",
        "# Mean calculations\n",
        "print(\"Mean of the third row:\", np.mean(dataset[2]))  # Mean of the third row\n",
        "print(\"Mean of the last column:\", np.mean(dataset[:, -1]))  # Mean of the last column\n",
        "print(\"Mean of the intersection of the first 3 rows & columns 1-3:\", np.mean(dataset[0:3, 0:3]))  # Mean of the first 3 rows and 3 columns\n",
        "\n",
        "# Median calculations\n",
        "print(\"Median of the last row:\", np.median(dataset[-1]))  # Median of the last row\n",
        "print(\"Median of the last 3 columns:\", np.median(dataset[:, -3:]))  # Median of the last 3 columns\n",
        "print(\"Median of each row:\", np.median(dataset, axis=1))  # Median of each row\n",
        "\n",
        "# Variance calculation\n",
        "print(\"Variance of the first two elements in the last row:\", np.var(dataset[-1, :2]))  # Variance of the first two elements in the last row\n",
        "\n",
        "# Standard deviation\n",
        "print(\"Standard deviation for the dataset:\", np.std(dataset))  # Standard deviation of the dataset\n",
        "\n",
        "# Indexing\n",
        "print(\"First row of the dataset:\", dataset[0])  # First row\n",
        "print(\"Last row of the dataset:\", dataset[-1])  # Last row\n",
        "print(\"First value of the first row:\", dataset[0, 0])  # First value of the first row\n",
        "print(\"Last value of the second-to-last row:\", dataset[-2, -1])  # Last value of the second-to-last row\n",
        "\n",
        "# Slicing\n",
        "print(\"Sliced (2x2) of the first 2 rows and first 2 columns:\", dataset[1:3, 1:2])  # Slicing first 3 rows and 2 columns\n",
        "print(\"Every second element of the 5th row:\", dataset[4, ::2])  # Every second element of the 5th row\n",
        "print(\"First 2 rows in reversed order:\", dataset[:2, ::-1])  # Reversing the entry order for the first 2 rows\n",
        "\n",
        "# Splitting\n",
        "# Split the dataset vertically into 2 parts\n",
        "ver_splits = np.vsplit(dataset, 2)\n",
        "print(\"Shape of dataset:\", dataset.shape)\n",
        "print(\"Shape of subset after vertical split:\", ver_splits[0].shape)\n",
        "\n",
        "# Iterating\n",
        "ever_index = 0\n",
        "for x in np.nditer(dataset):\n",
        "    print(x, ever_index)\n",
        "    ever_index += 1\n",
        "\n",
        "# Iterating with index matching the position\n",
        "for index, value in np.ndenumerate(dataset):\n",
        "    print(index, value)\n",
        "\n",
        "# Filtering: Print values greater than 105\n",
        "print(\"Values greater than 105:\", dataset[dataset > 105])\n",
        "\n",
        "# Extract values between 90 and 95\n",
        "print(\"Values between 90 and 95:\", np.extract((dataset > 90) & (dataset < 95), dataset))\n",
        "\n",
        "# Find the rows and columns where the absolute difference from 100 is less than 1\n",
        "rows, cols = np.where(np.abs(dataset - 100) < 1)\n",
        "print(\"Positions where abs(dataset - 100) < 1:\", [[rows[index], cols[index]] for index in range(len(rows))])\n",
        "\n",
        "# Sorting\n",
        "print(\"Sorted dataset (flattened):\", np.sort(dataset))\n",
        "print(\"Sorted dataset by columns:\", np.sort(dataset, axis=0))\n",
        "\n",
        "# Sorting a row (0th row in this case)\n",
        "index_sorted = np.argsort(dataset[0])\n",
        "print(\"Sorted first row:\", dataset[0][index_sorted])\n",
        "\n",
        "# Combining: Splitting and recombining\n",
        "thirds = np.array_split(dataset, 3, axis=1)  # Split into 3 parts (columns)\n",
        "halfed_first = np.vsplit(thirds[0], 2)  # Split the first third vertically into 2\n",
        "print(\"First half of the first third:\", halfed_first[0])\n",
        "\n",
        "first_col = np.vstack([halfed_first[0], halfed_first[1]])  # Vertically stack the halves\n",
        "print(\"First column after vstack:\", first_col)\n",
        "\n",
        "# Horizontal stacking\n",
        "first_second_col = np.hstack([first_col, thirds[1]])  # Horizontal stack first_col with the second third\n",
        "print(\"First and second columns after hstack:\", first_second_col)\n",
        "\n",
        "final_combined = np.hstack([first_second_col, thirds[2]])  # Combine with the third third\n",
        "print(\"Final combined columns:\", final_combined)\n",
        "\n",
        "# Reshaping\n",
        "print(\"Reshaped dataset (1D):\", np.reshape(dataset, (1, -1)))  # Reshape to 1D array\n",
        "print(\"Reshaped dataset to (-1, 2):\", dataset.reshape(-1, 2))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rSiIyuc6TCeJ"
      },
      "outputs": [],
      "source": [
        "# 6a\n",
        "import geoplotlib\n",
        "\n",
        "from geoplotlib.utils import DataAccessObject\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "\n",
        "# Load the dataset\n",
        "\n",
        "try:\n",
        "\n",
        "    # Read the original dataset\n",
        "\n",
        "    data = pd.read_csv('bus.csv')\n",
        "\n",
        "\n",
        "\n",
        "    # Check for required columns\n",
        "\n",
        "    if 'lat' not in data.columns or 'lon' not in data.columns:\n",
        "\n",
        "        print(\"Adding dummy geographical data ('lat' and 'lon') for testing.\")\n",
        "\n",
        "\n",
        "\n",
        "        # Add dummy latitude and longitude columns\n",
        "\n",
        "        # You can replace these values with real coordinates if needed\n",
        "\n",
        "        data['lat'] = [12.9716, 13.0827, 28.7041, 19.0760, 22.5726, 0, 0]\n",
        "\n",
        "        data['lon'] = [77.5946, 80.2707, 77.1025, 72.8777, 88.3639, 0, 0]\n",
        "\n",
        "\n",
        "\n",
        "    # Save the modified dataset (optional)\n",
        "\n",
        "    data.to_csv('bus_with_coords.csv', index=False)\n",
        "\n",
        "\n",
        "\n",
        "    # Create a DataAccessObject for geoplotlib\n",
        "\n",
        "    geodata = DataAccessObject.from_dataframe(data)\n",
        "\n",
        "\n",
        "\n",
        "    # Plot the points on the map\n",
        "\n",
        "    geoplotlib.dot(geodata)\n",
        "\n",
        "    geoplotlib.show()\n",
        "\n",
        "\n",
        "\n",
        "except FileNotFoundError:\n",
        "\n",
        "    print(\"Error: The file 'bus.csv' was not found. Please check the file path.\")\n",
        "\n",
        "except Exception as e:\n",
        "\n",
        "    print(f\"An error occurred: {e}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PwR0tsTYTCeK"
      },
      "outputs": [],
      "source": [
        "# 6b\n",
        "\n",
        "import geoplotlib\n",
        "\n",
        "from geoplotlib.utils import DataAccessObject\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "\n",
        "# Load the dataset\n",
        "\n",
        "try:\n",
        "\n",
        "    # Read the original dataset\n",
        "\n",
        "    data = pd.read_csv('bus.csv')\n",
        "\n",
        "\n",
        "\n",
        "    # Check for required columns\n",
        "\n",
        "    if 'lat' not in data.columns or 'lon' not in data.columns:\n",
        "\n",
        "        print(\"Adding dummy geographical data ('lat' and 'lon') for testing.\")\n",
        "\n",
        "\n",
        "\n",
        "        # Add dummy latitude and longitude columns\n",
        "\n",
        "        # You can replace these values with real coordinates if needed\n",
        "\n",
        "        data['lat'] = [12.9716, 13.0827, 28.7041, 19.0760, 22.5726, 0, 0]\n",
        "\n",
        "        data['lon'] = [77.5946, 80.2707, 77.1025, 72.8777, 88.3639, 0, 0]\n",
        "\n",
        "\n",
        "\n",
        "    # Save the modified dataset (optional)\n",
        "\n",
        "    data.to_csv('bus_with_coords.csv', index=False)\n",
        "\n",
        "\n",
        "\n",
        "    # Create a DataAccessObject for geoplotlib\n",
        "\n",
        "    geodata = DataAccessObject.from_dataframe(data)\n",
        "\n",
        "\n",
        "\n",
        "    # Plot the points on the map\n",
        "\n",
        "    geoplotlib.dot(geodata)\n",
        "\n",
        "    geoplotlib.show()\n",
        "\n",
        "\n",
        "\n",
        "except FileNotFoundError:\n",
        "\n",
        "    print(\"Error: The file 'bus.csv' was not found. Please check the file path.\")\n",
        "\n",
        "except Exception as e:\n",
        "\n",
        "    print(f\"An error occurred: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "Hd2CaKeuTCeK"
      },
      "outputs": [],
      "source": [
        "# 7a)\n",
        "import folium\n",
        "my_map1 = folium.Map(location = [28.5011226, 77.4099794],zoom_start = 12 )\n",
        "my_map1.save(\" my_map1.html \")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "eVC1rWYZTCeK"
      },
      "outputs": [],
      "source": [
        "# 7b)\n",
        "import folium\n",
        "my_map2 = folium.Map(location = [28.5011226, 77.4099794],zoom_start = 12)\n",
        "folium.CircleMarker(location = [28.5011226, 77.4099794],radius = 50, popup = ' FRI ').add_to(my_map2)\n",
        "my_map2.save(\" my_map2.html \")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "O7uhumKmTCeL"
      },
      "outputs": [],
      "source": [
        "# 7c)\n",
        "import folium\n",
        "my_map3 = folium.Map(location = [28.5011226, 77.4099794],zoom_start = 15)\n",
        "folium.Marker([28.5011226, 77.4099794],popup = ' Geeksforgeeks.org ').add_to(my_map3)\n",
        "my_map3.save(\" my_map3.html \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_KOxMnznTCeL"
      },
      "outputs": [],
      "source": [
        "# 7d)\n",
        "import folium\n",
        "my_map4 = folium.Map(location=[28.5011226, 77.4099794], zoom_start=12)\n",
        "folium.Marker([28.704059, 77.102490], popup='Delhi').add_to(my_map4)\n",
        "folium.Marker([28.5011226, 77.4099794], popup='GeeksforGeeks').add_to(my_map4)\n",
        "folium.PolyLine(locations=[(28.704059, 77.102490), (28.5011226, 77.4099794)], line_opacity=0.5).add_to(my_map4)\n",
        "my_map4.save(\"my_map4.html\")\n",
        "import os\n",
        "print(os.getcwd())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b-4bJzpsTCeL"
      },
      "outputs": [],
      "source": [
        "#8th a\n",
        "\n",
        "from bokeh.plotting import figure, show\n",
        "from bokeh.io import output_notebook\n",
        "from bokeh.models import Legend, LegendItem\n",
        "import numpy as np\n",
        "\n",
        "output_notebook()\n",
        "\n",
        "x = np.linspace(0, 10, 100)\n",
        "y = np.sin(x)\n",
        "y2 = np.cos(x)\n",
        "\n",
        "def line_plot_with_annotations():\n",
        "    p = figure(title=\"Line Plot with Annotations and Legends\", x_axis_label='X', y_axis_label='Y', width=800, height=400)\n",
        "\n",
        "    line1 = p.line(x, y, line_width=2, color=\"blue\")\n",
        "    line2 = p.line(x, y2, line_width=2, color=\"green\")\n",
        "\n",
        "    p.text(x=[5], y=[0.5], text=[\"Peak of sin(x)\"], text_align=\"center\", text_font_size=\"12pt\")\n",
        "    p.text(x=[8], y=[-0.5], text=[\"Peak of cos(x)\"], text_align=\"center\", text_font_size=\"12pt\")\n",
        "\n",
        "    legend = Legend(items=[\n",
        "        LegendItem(label=\"sin(x)\", renderers=[line1]),\n",
        "        LegendItem(label=\"cos(x)\", renderers=[line2])\n",
        "    ])\n",
        "\n",
        "    p.add_layout(legend, 'right')\n",
        "\n",
        "    show(p)\n",
        "\n",
        "line_plot_with_annotations()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hknw9SMsTCeL"
      },
      "outputs": [],
      "source": [
        "\n",
        "#8th b\n",
        "\n",
        "\n",
        "from bokeh.plotting import figure, show\n",
        "from bokeh.io import output_notebook\n",
        "import numpy as np\n",
        "\n",
        "output_notebook()\n",
        "\n",
        "def scatter_plot():\n",
        "    x = np.random.rand(50) * 10\n",
        "    y = np.random.rand(50) * 10\n",
        "    colors = np.random.choice(['red', 'green', 'blue', 'purple'], size=50)\n",
        "\n",
        "    p = figure(title=\"Random Scatter Plot\", x_axis_label='X', y_axis_label='Y', width=800, height=400)\n",
        "\n",
        "    scatter = p.circle(x, y, size=8, color=colors, alpha=0.6)\n",
        "    scatter.name = \"Data Points\"\n",
        "\n",
        "    show(p)\n",
        "\n",
        "scatter_plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xbj9aTPsTCeL"
      },
      "outputs": [],
      "source": [
        "# 9\n",
        "%matplotlib inline\n",
        "import urllib.request\n",
        "from bs4 import BeautifulSoup\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Correct URL format\n",
        "url = \"https://www.geeksforgeeks.org/how-to-automate-an-excel-sheet-in-python/?ref=feed\"\n",
        "\n",
        "# Fetch HTML from the URL\n",
        "html = urllib.request.urlopen(url)\n",
        "\n",
        "# Parse HTML using BeautifulSoup\n",
        "htmlParse = BeautifulSoup(html, 'html.parser')\n",
        "\n",
        "# Extract the first <p> tag and get its text\n",
        "p = htmlParse.find(\"p\").get_text()\n",
        "\n",
        "# Print the extracted paragraph for verification\n",
        "print(p)\n",
        "\n",
        "# Function to count vowels and consonants\n",
        "def Cvc(text):\n",
        "    vowels = 'AEIOUaeiou'\n",
        "    vowelcount = 0\n",
        "    consonentcount = 0\n",
        "\n",
        "    # Count vowels and consonants\n",
        "    for char in text:\n",
        "        if char.isalpha():  # Ensure the character is alphabetic\n",
        "            if char in vowels:\n",
        "                vowelcount += 1\n",
        "            else:\n",
        "                consonentcount += 1\n",
        "    return vowelcount, consonentcount\n",
        "\n",
        "# Get the counts of vowels and consonants\n",
        "vowelcount, consonentcount = Cvc(p)\n",
        "\n",
        "# Categories and values for pie chart\n",
        "categories = ['Vowels', 'Consonants']\n",
        "values = [vowelcount, consonentcount]\n",
        "\n",
        "# Print the counts for verification\n",
        "print(f\"Vowel count: {vowelcount}, Consonant count: {consonentcount}\")\n",
        "\n",
        "# Create a pie chart\n",
        "plt.pie(values, labels=categories, autopct='%1.1f%%', startangle=90)\n",
        "plt.title('Vowel and Consonant Distribution')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
